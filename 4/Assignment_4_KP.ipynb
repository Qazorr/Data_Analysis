{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Today we are going to perform the simple classification of the amazon reviews' sentiment.\n",
    "\n",
    "### Please, download the dataset amazon_baby.csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Planetwise Flannel Wipes</td>\n",
       "      <td>These flannel wipes are OK, but in my opinion ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Planetwise Wipe Pouch</td>\n",
       "      <td>it came early and was not disappointed. i love...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Annas Dream Full Quilt with 2 Shams</td>\n",
       "      <td>Very soft and comfortable and warmer than it l...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>This is a product well worth the purchase.  I ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>All of my kids have cried non-stop when I trie...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name  \\\n",
       "0                           Planetwise Flannel Wipes   \n",
       "1                              Planetwise Wipe Pouch   \n",
       "2                Annas Dream Full Quilt with 2 Shams   \n",
       "3  Stop Pacifier Sucking without tears with Thumb...   \n",
       "4  Stop Pacifier Sucking without tears with Thumb...   \n",
       "\n",
       "                                              review  rating  \n",
       "0  These flannel wipes are OK, but in my opinion ...       3  \n",
       "1  it came early and was not disappointed. i love...       5  \n",
       "2  Very soft and comfortable and warmer than it l...       5  \n",
       "3  This is a product well worth the purchase.  I ...       5  \n",
       "4  All of my kids have cried non-stop when I trie...       5  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "class colors:\n",
    "    POSITIVE = '\\033[92m'\n",
    "    NEGATIVE = '\\033[91m'\n",
    "    RESET = '\\033[0m'\n",
    "\n",
    "iterations = 2000\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    import string\n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    return text.translate(translator)\n",
    "\n",
    "baby_df = pd.read_csv('amazon_baby.csv')\n",
    "baby_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1 (data preparation)\n",
    "a) Remove punctuation from reviews using the given function.   \n",
    "b) Replace all missing (nan) revies with empty \"\" string.  \n",
    "c) Drop all the entries with rating = 3, as they have neutral sentiment.   \n",
    "d) Set all positive ($\\geq$ 4) ratings to 1 and negative($\\leq$ 2) to -1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "Review before: This is a product well worth the purchase.  I have not found anything else like this, and it is a positive, ingenious approach to losing the binky.  What I love most about this product is how much ownership my daughter has in getting rid of the binky.  She is so proud of herself, and loves her little fairy.  I love the artwork, the chart in the back, and the clever approach of this tool.\n",
      "\n",
      "Review after: This is a product well worth the purchase  I have not found anything else like this and it is a positive ingenious approach to losing the binky  What I love most about this product is how much ownership my daughter has in getting rid of the binky  She is so proud of herself and loves her little fairy  I love the artwork the chart in the back and the clever approach of this tool\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#a)\n",
    "\n",
    "#short test: \n",
    "baby_df[\"review\"][4] == 'All of my kids have cried nonstop when I tried to ween them off their pacifier until I found Thumbuddy To Loves Binky Fairy Puppet  It is an easy way to work with your kids to allow them to understand where their pacifier is going and help them part from itThis is a must buy book and a great gift for expecting parents  You will save them soo many headachesThanks for this book  You all rock'\n",
    "print(remove_punctuation(baby_df[\"review\"][4]) == 'All of my kids have cried nonstop when I tried to ween them off their pacifier until I found Thumbuddy To Loves Binky Fairy Puppet  It is an easy way to work with your kids to allow them to understand where their pacifier is going and help them part from itThis is a must buy book and a great gift for expecting parents  You will save them soo many headachesThanks for this book  You all rock')\n",
    "###########\n",
    "\n",
    "print(f'Review before: {baby_df[\"review\"][3]}', end='\\n\\n')\n",
    "\n",
    "baby_df['review'] = baby_df['review'].apply(lambda x: remove_punctuation(x) if isinstance(x, str) else '')\n",
    "\n",
    "print(f'Review after: {baby_df[\"review\"][3]}', end='\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note:\n",
    "    As we can see the punctuation in the review dissapeared - which be useful when we vectorize our data later (to analize it), because we won't have punctuation symbols in the vector that could destroy our model (because most of the people use some kind of punctuation symbols and they dont serve any meaning for us because we are interested in sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [name, review, rating]\n",
      "Index: []\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#b) done in a)\n",
    "# check whether all rows do not have nan as the value in review column\n",
    "print(baby_df[baby_df['review'].isna()])\n",
    "#short test:\n",
    "baby_df[\"review\"][38] == baby_df[\"review\"][38]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note:\n",
    "    All reviews with no review value ('nan' as a value) now are just empty strings which can be taken into consideration when making a vector. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of rows in which rating column is 3: 0\n"
     ]
    }
   ],
   "source": [
    "#c)\n",
    "baby_df = baby_df[baby_df.rating != 3]\n",
    "#short test:\n",
    "print(f'Amount of rows in which rating column is 3: {sum(baby_df[\"rating\"] == 3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note:\n",
    "    We succesfully dropped all data in which rating was 3 (so the neutral ones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of ratings with ratting different than -1 or 1: 0\n"
     ]
    }
   ],
   "source": [
    "#d) \n",
    "baby_df.loc[baby_df[\"rating\"] <= 2, \"rating\"] = -1\n",
    "baby_df.loc[baby_df[\"rating\"] >= 4 , \"rating\"] = 1\n",
    "\n",
    "#short test:\n",
    "print(f'Amount of ratings with ratting different than -1 or 1: {sum(baby_df[\"rating\"]**2 != 1)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note:\n",
    "    We succesfully changed all negative ratings to -1 and positive to 1, so that it's easier to work with the classified data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CountVectorizer\n",
    "In order to analyze strings, we need to assign them numerical values. We will use one of the simplest string representation, which transforms strings into the $n$ dimensional vectors. The number of dimensions will be the size of our dictionary, and then the values of the vector will represent the number of appereances of the given word in the sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['adore' 'and' 'apples' 'bananas' 'dislike' 'hate' 'like' 'oranges' 'they'\n",
      " 'we']\n",
      "[[0 0 1 0 0 0 1 0 0 1]\n",
      " [0 0 0 0 0 1 0 1 0 1]\n",
      " [1 0 0 1 0 0 0 0 0 0]\n",
      " [0 1 1 0 0 0 2 1 0 1]\n",
      " [0 0 0 1 1 0 0 0 1 0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "reviews_train_example = [\n",
    "    \"We like apples\",\n",
    "    \"We hate oranges\",\n",
    "    \"I adore bananas\",\n",
    "    \"We like like apples and oranges\",\n",
    "    \"They dislike bananas\"\n",
    "]\n",
    "\n",
    "X_train_example = vectorizer.fit_transform(reviews_train_example)\n",
    "\n",
    "print(vectorizer.get_feature_names_out())\n",
    "print(X_train_example.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 1 0 0 1 0 1 0]\n",
      " [0 1 1 1 0 1 0 1 0 1]\n",
      " [0 0 0 1 0 0 0 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "reviews_test_example = [\"They like bananas\",\n",
    "                   \"We hate oranges bananas and apples\",\n",
    "                   \"We love bananas\"] #New word!\n",
    "\n",
    "X_test_example = vectorizer.transform(reviews_test_example)\n",
    "\n",
    "print(X_test_example.todense())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should acknowledge few facts. Firstly, CountVectorizer does not take order into account. Secondly, it ignores one-letter words (this can be changed during initialization). Finally, for test values, CountVectorizer ignores words which are not in it's dictionary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2 \n",
    "a) Split dataset into training and test sets.     \n",
    "b) Transform reviews into vectors using CountVectorizer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#a)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "smaller_df = baby_df[:]\n",
    "X_train, X_test, y_train, y_test = train_test_split(smaller_df['review'], smaller_df['rating'], test_size=0.3, random_state=44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(116726, 111592)\n"
     ]
    }
   ],
   "source": [
    "#b)\n",
    "vectorizer = CountVectorizer()\n",
    "X_train = vectorizer.fit_transform(X_train)\n",
    "# print(np.where(np.array(vectorizer.get_feature_names_out()) == ' '))\n",
    "X_test = vectorizer.transform(X_test)\n",
    "print(np.shape(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note:\n",
    "    We made our vectorization using the training dataset (part of the original dataset [0.3 of the dataset to be exact]). \n",
    "    \n",
    "    The size of the vector (116726 x 11592) is huge because of the amount of data in our dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3 \n",
    "a) Train LogisticRegression model on training data (reviews processed with CountVectorizer, ratings as they were).   \n",
    "b) Print 10 most positive and 10 most negative words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=2000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=2000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=2000)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#a)\n",
    "model = LogisticRegression(max_iter=iterations)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note:\n",
    "    We succesfully trained our LogisticRegression model using the traning data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most positive words: rich ply thankful awesome pleasantly minor worry lifesaver perfect downside\n",
      "Most negative words: dissapointed disappointing worst worthless poorly useless nope shame pointless theory\n"
     ]
    }
   ],
   "source": [
    "#b)\n",
    "coefs = model.coef_.reshape(-1, 1)\n",
    "new_coefs = np.array([coef[0] for coef in coefs])\n",
    "\n",
    "most_positive_idx = (-new_coefs).argsort()[:10]\n",
    "most_negative_idx = new_coefs.argsort()[:10]\n",
    "\n",
    "most_positive = [vectorizer.get_feature_names_out()[i] for i in most_positive_idx]\n",
    "most_negative = [vectorizer.get_feature_names_out()[i] for i in most_negative_idx]\n",
    "\n",
    "print('Most positive words:', *most_positive)\n",
    "print('Most negative words:', *most_negative)\n",
    "\n",
    "#hint: model.coef_, vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note:\n",
    "    We can see that the positive and the negative words fit nicely in their category (even though there are some exceptions like 'downside' in positive words [probably because most people when giving product reviews like to also list their downsides so that the review can mean more to other people wanting to buy something.])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4 \n",
    "a) Predict the sentiment of test data reviews.   \n",
    "b) Predict the sentiment of test data reviews in terms of probability.   \n",
    "c) Find five most positive and most negative reviews.   \n",
    "d) Calculate the accuracy of predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#a)\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#b)\n",
    "y_pred_prob = model.predict_proba(X_test)\n",
    "#hint: model.predict_proba()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most negative reviews row numbers: 22799 24865 40068 46409 17196\n",
      "Most positive reviews row numbers: 28974 24539 38946 709 29309\n",
      "\u001b[91mred \u001b[0m means a negative review (value == -1)\n",
      "\u001b[92mgreen \u001b[0m means a positive review (value == 1)\n",
      "\n",
      "------------Most positive reviews according to probability------------\n",
      "\t\u001b[92m28974:\u001b[0m Great for a night over at Grandmas house  My grandson enjoyed it and the parents gave it a thumbs up\n",
      "\t\u001b[92m24539:\u001b[0m this gate and extension are grate they look good and work good  that is if you follow the directions If you dont reed the directions you will thank it is broken but it is not it will all make seance wants it is installed\n",
      "\t\u001b[92m38946:\u001b[0m Both my 4 year old and 6 month old are wonderful shoppers but on a marathon shopping day when I am by myself my 4 year old does get a little weary of treading around behind me  He thinks he is too grown up for a baby stroller but was very excited to see the big boy seat on the back of his babys stroller  This stroller is awesome  It caters for both of their needs without cramping my style or theirs  He can sit stand or kneel and I think the best part about it is that the chioce is his  The baby is also well catered for in his comfy upfront seat  We just got back from a vacation to Mexico and this stroller was perfect  The adjustable hood came all the way sheilding the little guy from the sun and wind and the basket had more than enough room for purchases  My 6 year old neice even had a turn  The parent organizer is really neat we held up to 4 drinks in it at a time and they even stayed cool with the neoprene insulation  Another plus is how light the stroller is to pick up and it is so easy to collapse and put up again  The only downfall about the stroller is the amount of times you will be stopped by passersby who want to know all about it and where you got it  We love Joovy\n",
      "\t\u001b[92m709:\u001b[0m The product itself works great its just a little hard to use Its a little difficult to get the sides squeezed to get it open and if your cord is larger than the standard size its a little tight But it keeps the little people out\n",
      "\t\u001b[91m29309:\u001b[0m This is a 45 star product  Makes a potentially slippery bath tub safer and more comfortable for a babyThe EXACT same product is available at Babies R Us for 399 not 3999  Four dollars or Forty  You make the call\n",
      "\n",
      "------------Most negative reviews according to probability------------\n",
      "\t\u001b[92m22799:\u001b[0m You may be wondering thatMost of the other Medela pumps have little nubs that you attach the tubing to and thats how the pumping action works  The air is sucked through the tubes into the shield and there you goThe Symphony is a hospital grade breast pump but whats more its also safe for sharing which is why some workplaces have them  Instead of having air sucked directly through the machine it has these two pistons at the top and those pistons as they go up and down are responsible for the suction  But to convert an up and down piston motion into sucking you need a special attachment  THATs whats specific to this kit vs the other medela kits that might  include tubing and shields and bottles  If you dont have those attachments you cannot connect to the symphony end of storySo this is a good kit  But you only need one like this since the Symphony specific parts do not get dirty and dont need to be washed really  Once you have this if you want more shields and bottles you can buy one of many other medela kits that dont include the extra symphony partsThat said this kit includes everything you need to pump with the symphony  You dont need anything else  But as an aside it does not include nipples for the bottles  Not that it needs to  just saying if you are buying this kit to grab and go somewhere and then want to give the bottles for feeding you need nipples for the bottles or you need other bottles  Aside from that this includes everything you need and you dont need anything moreIf you are buying this to pump at work I would highly recommend the medela quick clean wipes which lets you clean all the pumping parts without a sink  just a quick wipe down so you can toss them back into your bag and be good to go  httpwwwamazoncomQuickCleanBreastpumpAccessoryWipesdpB000CCXLNE\n",
      "\t\u001b[92m24865:\u001b[0m Wasnt hard to assemble just follow the directions My husband didnt use the screws that came with the dresser to screw the backing on instead he used nails which were easier to insert\n",
      "\t\u001b[92m40068:\u001b[0m This product saved our car rides quite a few times having a boy thats difficult to potty train and stubborn enough to insist on underwear It was washed over and over in Hot water no fabric softener and still looked and felt brandnew Only problem we had was the center where the seat belt goes through seemed to leak through once and a while\n",
      "\t\u001b[92m46409:\u001b[0m I almost didnt buy a new gate and figured i would save the money and struggle with the old plastic one I had I could not be happier that I bought this Its only three days old so i cant speak for how it ages The latch works perfect and install took second The only problem was it was very heavy to get out of the box It you want it too lock behind you then you have to let it slam shut The opening is kinda small as other people have noted but its wide enough to walk thru while holding my dog The color is a really nice brown with black hardware My dog tends to jump all the other gates but this one is tall enough to keep her from even thinking about it Also the fact that its metal keeps my puppy from chewing it like he did the plastic ones\n",
      "\t\u001b[92m17196:\u001b[0m We love this monitor  You could live with a simple sound monitor but my husband and I love gadgets so we both agreed to get this despite the cost  Our daughter is now 3 months  It has the obvious benefits of being able to see her when sleeping and to check in on her when we hear noises but dont want to go into the room if it is not necessary  An added bonus is to use the monitor as a nightlightflashlight when I go to her room for those late night feedings  We recently moved and this has proved to be invaluable to help me navigate around boxes in the hall  Battery life is great  I plug it in at night and use it all day around the house  The one down side is that I cannot talk on our wireless house phone in our daughters room without turning off the base because the frequencies interfere with each otherI have also found the video monitor to be valuable when babysitting older children who can get out of their cribbed  It lets me watch them and know when I need to go into the room to put them back in bed   When we no longer need it for our children I will probably use it to watch the dog at night\n",
      "----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#c) \n",
    "negative = y_pred_prob[:, 0]\n",
    "positive = y_pred_prob[:, 1]\n",
    "most_negative_idx = (-negative).argsort()[:5]\n",
    "most_positive_idx = positive.argsort()[-5:]\n",
    "\n",
    "print('Most negative reviews row numbers:', *most_negative_idx)\n",
    "print('Most positive reviews row numbers:', *most_positive_idx)\n",
    "\n",
    "print(f'{colors.NEGATIVE}red {colors.RESET} means a negative review (value == -1)')\n",
    "print(f'{colors.POSITIVE}green {colors.RESET} means a positive review (value == 1)')\n",
    "\n",
    "_ = 'Most positive reviews according to probability'\n",
    "print(f'\\n{_:-^70}')\n",
    "for idx in most_positive_idx:\n",
    "    color = colors.POSITIVE if np.array(smaller_df['rating'])[idx] == 1 else colors.NEGATIVE\n",
    "    print(f'\\t{color}{idx}:{colors.RESET}', np.array(smaller_df['review'])[idx])\n",
    "\n",
    "_ = _.replace('positive', 'negative')\n",
    "print(f'\\n{_:-^70}')\n",
    "for idx in most_negative_idx:\n",
    "    color = colors.POSITIVE if np.array(smaller_df['rating'])[idx] == 1 else colors.NEGATIVE\n",
    "    print(f'\\t{color}{idx}:{colors.RESET}',np.array(smaller_df['review'])[idx])\n",
    "print('-'*70)\n",
    "#hint: use the results of b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note:\n",
    "    From the reviews we can see that most of them are positive (when it comes to original ranking) but the model predicted some of them as positive and other as negative.\n",
    "    \n",
    "    What I found really interesting is that the longer the review the more probable it is that the model specifies it as the negative review (which is probably because the density of words are high and words can serve multiple meanings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model score: 0.9318154559628993\n"
     ]
    }
   ],
   "source": [
    "#d) \n",
    "print(f'Model score: {model.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note:\n",
    "    The model achieved a score of 0.931 which is a high score - which also means that the training and testing data was correctly split."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5\n",
    "In this exercise we will limit the dictionary of CountVectorizer to the set of significant words, defined below.\n",
    "\n",
    "\n",
    "a) Redo exercises 2-5 using limited dictionary.   \n",
    "b) Check the impact of all the words from the dictionary.   \n",
    "c) Compare accuracy of predictions and the time of evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "significant_words = ['love','great','easy','old','little','perfect','loves','well','able','car','broke','less','even','waste','disappointed','work','product','money','would','return']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most positive words: loves perfect love easy great little well able old car\n",
      "Most negative words: disappointed return waste broke money work even would product less\n",
      "\n",
      "Most positive reviews row numbers: 6473 19348 16281 40378 28924\n",
      "Most negative reviews row numbers: 11091 1403 10376 11231 39845\n",
      "\n",
      "\u001b[91mred \u001b[0m means a negative review (value == -1)\n",
      "\u001b[92mgreen \u001b[0m means a positive review (value == 1)\n",
      "\n",
      "------------Most positive reviews according to probability------------\n",
      "\t\u001b[91m6473:\u001b[0m I registered for this monitor because of the two receiver feature and because the 900 mHz technology was supposed to be the best  We already used the Fisher Price prenatal to nursery monitor during my pregnancy but we thought that this one would be better for everyday use  From day one there was static but I just thought that all monitors must do that  It got worse with time neither channel would come in clearly the second channel never did work we would get a loud static noise about every 30 seconds that was impossible to sleep through and it would pick up phone conversations from our neighbor every night at midnight  Still we figured it was because we lived in a subdivision with several neighbors and baby monitors  However the real test was when we visited my husbands parents at their country home  There are NO neighbors there nothing to interfere and the monitor was still so full of static that we couldnt hear our son  Finally one night out of desperation we pulled out the old Fisher Price monitor  It was totally staticfree and we are still using it  The Peace of Mind monitor will go in the trash\n",
      "\t\u001b[91m19348:\u001b[0m This the first review Ive ever written and Im only doing it to save somebody else some money  This has got to be the worst monitor ever  Ive used it for less than 2 years and it is just horrible Horrible reception horrible battery life and now I cant even get sound from it unless I wiggle the plug into it  One of the receivers is taped up and I still only get sound every once  a while  I have to buy a new baby monitor  Very disappointed  Would have given it negative stars if I could have\n",
      "\t\u001b[91m16281:\u001b[0m Absolutely not what I expect Very small doesnt hold but 3 animals Next time dimensions should be listed in description\n",
      "\t\u001b[92m40378:\u001b[0m Much cheaper than a similar brush I saw at Walmart  I use this brush daily to clean out my stainless steel coffee thermos\n",
      "\t\u001b[92m28924:\u001b[0m We bought this when our toddler grandson decided he was too grown up for a crib At home he sleeps in a toddler bed and we knew hed resist going back into a crib when he occasionally sleeps over at our house Hes a restless sleeper and isnt quite ready to spend a night in a regular twin size bed The Regalo cot is similar to the ones used at his day care It sets up in less than a minute and is sturdy and long enough to accomodate him as he grows Its low enough to the floor so that he can get on and off without assistance and he wont get hurt if he falls offWe paired the cot with an inexpensive sleeping bag and when its bedtime we make it a camping adventure for him Grandma likes the removable washable cover that is supplied with it and the way the cot folds into its own bag for storagePROS Compact lightweight sturdy removable and washable cover comes with a storagecarry bag Easy to set up and take down Great for travel and occasional sleepoversCONS We havent found any yet\n",
      "\n",
      "------------Most negative reviews according to probability------------\n",
      "\t\u001b[92m11091:\u001b[0m My newborn very colicky baby would NOT sleep anywhere but ON TOP of my chest which was exhausting and not safe When I moved her into her big crib shed wake easily and scream This gem was the ideal solution Id move her into this after she was asleep and place it in the middle of our queen bed king size would be optimal though Amazingly shes sleep for 68 hours stretches AT NIGHT in this little bed despite the snores of my hubby and I on either side of her This thing helped us all get some order and sanity into our routine and more importantly helped her rest The down side is she outgrew after about 6 weeks but I would buy it again in a second   worth every penny She just needed to be close to me and this worked beautifully Afterward she moved to a cosleeper which was also great and eventually at about 45 months her big crib I highly recommend it No concerns about safety or rolling on top as the sides are well reinforced and the little light is handy for checking up in the middle of the night If youre a stressed out mother with a colicky  needy baby  please try this though note I always put her in sleeping and once she was in that was her for the night even at 2 weeks old\n",
      "\t\u001b[91m1403:\u001b[0m Did not meet my expectations I guess you get what you pay for The product was smaller than advertised My 2 year old likes it and thats all that matters \n",
      "\t\u001b[92m10376:\u001b[0m Love this chair Started my 4 month old in it He loves it Its nice how its adjustable w age so hell be using it for many more months Also very durable and easy to clean A def steal for the price Buy it you will enjoy\n",
      "\t\u001b[92m11231:\u001b[0m The product went on easy when following the instructions to use alcohol first and it has continued to stickI like that it is soft for my son as well as I can still see most of my furniture through it as compared to the fabric rails which may or may not match the rest of his roomShipping also went smoothly and I received it on time\n",
      "\t\u001b[92m39845:\u001b[0m \n",
      "----------------------------------------------------------------------\n",
      "Model score: 0.8682285211689921\n"
     ]
    }
   ],
   "source": [
    "#a)\n",
    "X_train, X_test, y_train, y_test = train_test_split(smaller_df['review'], smaller_df['rating'], test_size=0.3, random_state=44)\n",
    "vectorizer = CountVectorizer(vocabulary=significant_words)\n",
    "X_train = vectorizer.fit_transform(X_train)\n",
    "X_test = vectorizer.transform(X_test)\n",
    "model = LogisticRegression(max_iter=iterations)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "coefs = model.coef_.reshape(-1, 1)\n",
    "new_coefs = np.array([coef[0] for coef in coefs])\n",
    "\n",
    "most_positive_idx = (-new_coefs).argsort()[:10]\n",
    "most_negative_idx = new_coefs.argsort()[:10]\n",
    "\n",
    "most_positive = [vectorizer.get_feature_names_out()[i] for i in most_positive_idx]\n",
    "most_negative = [vectorizer.get_feature_names_out()[i] for i in most_negative_idx]\n",
    "\n",
    "print('Most positive words:', *most_positive)\n",
    "print('Most negative words:', *most_negative, end='\\n\\n')\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_prob = model.predict_proba(X_test)\n",
    "negative = y_pred_prob[:, 0]\n",
    "positive = y_pred_prob[:, 1]\n",
    "\n",
    "most_negative_idx = (-negative).argsort()[:5]\n",
    "most_positive_idx = positive.argsort()[-5:]\n",
    "print('Most positive reviews row numbers:', *most_positive_idx)\n",
    "print('Most negative reviews row numbers:', *most_negative_idx, end='\\n\\n')\n",
    "\n",
    "print(f'{colors.NEGATIVE}red {colors.RESET} means a negative review (value == -1)')\n",
    "print(f'{colors.POSITIVE}green {colors.RESET} means a positive review (value == 1)')\n",
    "\n",
    "_ = 'Most positive reviews according to probability'\n",
    "print(f'\\n{_:-^70}')\n",
    "for idx in most_positive_idx:\n",
    "    color = colors.POSITIVE if np.array(smaller_df['rating'])[idx] == 1 else colors.NEGATIVE\n",
    "    print(f'\\t{color}{idx}:{colors.RESET}', np.array(smaller_df['review'])[idx])\n",
    "\n",
    "_ = _.replace('positive', 'negative')\n",
    "print(f'\\n{_:-^70}')\n",
    "for idx in most_negative_idx:\n",
    "    color = colors.POSITIVE if np.array(smaller_df['rating'])[idx] == 1 else colors.NEGATIVE\n",
    "    print(f'\\t{color}{idx}:{colors.RESET}',np.array(smaller_df['review'])[idx])\n",
    "print('-'*70)\n",
    "\n",
    "print(f'Model score: {model.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note:\n",
    "    Using the limited dictionary we achieved worse results - the model score is now 0.868 (6.82% worse than the previous one).\n",
    "    \n",
    "    The positive reviews even though predicted as the most positive by the model were negative in the original dataset.\n",
    "\n",
    "    The interesting thing is that the empty review (39845) even though classified as a positive review (in the original dataset) was in the top negative reviews according to the model - which should be taken into consideration when analising such data (maybe we want to drop all the rows in which the reviews are empty as they do not participate as much in model prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91m-2.32503\u001b[0m: disappointed\n",
      "\u001b[91m-2.17067\u001b[0m: return\n",
      "\u001b[91m -1.9979\u001b[0m: waste\n",
      "\u001b[91m-1.73447\u001b[0m: broke\n",
      "\u001b[91m-0.92054\u001b[0m: money\n",
      "\u001b[91m-0.63547\u001b[0m: work\n",
      "\u001b[91m-0.51369\u001b[0m: even\n",
      "\u001b[91m-0.34632\u001b[0m: would\n",
      "\u001b[91m-0.30603\u001b[0m: product\n",
      "\u001b[91m-0.17897\u001b[0m: less\n",
      "\u001b[92m 0.05671\u001b[0m: car\n",
      "\u001b[92m 0.08259\u001b[0m: old\n",
      "\u001b[92m 0.19439\u001b[0m: able\n",
      "\u001b[92m 0.48143\u001b[0m: well\n",
      "\u001b[92m 0.48502\u001b[0m: little\n",
      "\u001b[92m 0.94037\u001b[0m: great\n",
      "\u001b[92m 1.14975\u001b[0m: easy\n",
      "\u001b[92m 1.34271\u001b[0m: love\n",
      "\u001b[92m 1.47255\u001b[0m: perfect\n",
      "\u001b[92m 1.70305\u001b[0m: loves\n"
     ]
    }
   ],
   "source": [
    "#b)\n",
    "coefs = np.array([coef for coef in model.coef_[0]])\n",
    "idx = coefs.argsort()\n",
    "for i in idx:\n",
    "    color = colors.POSITIVE if coefs[i] > 0 else colors.NEGATIVE\n",
    "    print(f'{color}{round(coefs[i],5):>8}{colors.RESET}: {vectorizer.get_feature_names_out()[i]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note:\n",
    "    We can see that the most negative words were: dissapointed, return, waste - all having negative meaning in english\n",
    "\n",
    "    When it comes to positive words they were: loves, perfect, easy - all of them having a very positive meaning\n",
    "    \n",
    "    So the model got the positive and negative words right (although words like 'car', 'product' don't have a very positive/negative meaning in english they were listed here because they were in a big amount of positive/negative reviews.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timing fit of model without limited dictionary...\n",
      "38.5 s ± 873 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "Model score: 0.9318154559628993\n",
      "\n",
      "Timing fit of model with limited dictionary...\n",
      "151 ms ± 1.81 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "Model score: 0.8682285211689921\n"
     ]
    }
   ],
   "source": [
    "#c)\n",
    "X_train, X_test, y_train, y_test = train_test_split(smaller_df['review'], smaller_df['rating'], test_size=0.3, random_state=44)\n",
    "vectorizer = CountVectorizer()\n",
    "X_train = vectorizer.fit_transform(X_train)\n",
    "X_test = vectorizer.transform(X_test)\n",
    "model = LogisticRegression(max_iter=iterations)\n",
    "print('Timing fit of model without limited dictionary...')\n",
    "%timeit model.fit(X_train, y_train)\n",
    "print(f'Model score: {model.score(X_test, y_test)}', end='\\n\\n')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(smaller_df['review'], smaller_df['rating'], test_size=0.3, random_state=44)\n",
    "vectorizer = CountVectorizer(vocabulary=significant_words)\n",
    "X_train = vectorizer.fit_transform(X_train)\n",
    "X_test = vectorizer.transform(X_test)\n",
    "model = LogisticRegression(max_iter=iterations)\n",
    "print('Timing fit of model with limited dictionary...')\n",
    "%timeit model.fit(X_train, y_train)\n",
    "print(f'Model score: {model.score(X_test, y_test)}')\n",
    "#hint: %time, %timeit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note:\n",
    "    The time difference the model in which we used predefined vocabulary is enormous - because we do not have to analyze all of the words but only ones from the given vocabulary. \n",
    "    Of course because of that the score is worse (but we discussed it before, as it is the same model as previously)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "21c533348f67f502eabc569758b203ffa20ec3a8cd71fc4a8c028e54127dd2ae"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
